{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wrangle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table des matières\n",
    "* [Introduction](#intro)\n",
    "* [Rassemblement des données](#gathering)\n",
    "* [Evaluation des données](#assessing)\n",
    "* [Nettoyage des données](#cleaning)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction<a id='intro'></a>\n",
    "Le présent rapport résume en quelques lignes l'ensemble des travaux effectués dans la phase de préparation des données du projet **\"Préparation et analyse de données\"**. Il décrit ce qui a été fait dans les étapes successives de la préparation de données que sont : le rassemblement des données, l’évaluation des données et le nettoyage des données.\n",
    "\n",
    "\n",
    "### Rassemblement des données<a id='gathering'></a>\n",
    "\n",
    "Cette étape a consisté à charger dans un DataFrame que j'ai nommé **`dogs_rating`**, les données d’archives Tweeter (WeRateDogs) améliorées, mises à disposition par le projet. J'ai ensuite récupéré et chargé dans un DataFrame (**`image_predictions`**) les données de prédiction d’images accessibles via l’url (https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv) fournit dans le projet. En ce qui concerne les données supplémentaires à récupérer avec l’API Tweeter, pour des raisons personnelles j’ai préféré utiliser les données disponibles sans compte, tout en prenant soin de lire et de comprendre le code de l’API. Les données de l'API on été chargées dans le DataFrame **`additional_data`**.\n",
    "\n",
    "### Evaluation des données<a id='assessing'></a>\n",
    "\n",
    "Dans cette rubrique je me suis exercé à inspecter chaque ensemble de données à la recherche de problèmes de qualité et de problèmes d'ordre structurels. J’ai employé les deux techniques d’évaluation de données que sont l’évaluation visuelle et l’évaluation programmatique, le tout guidé par les dimensions de la qualité de données (complétude, validité, exactitude, cohérence). \n",
    "\n",
    "L’évaluation visuelle a permis d’identifier les problèmes de qualité tels que : \n",
    "* Les données manquantes dans les colonnes `retweeted_status_id,retweeted_status_user_id,retweeted_status_timestamp` du DataFrame  `dogs_rating` ;\n",
    "* des tweets ne comportant pas de nom de chien et d’autres pour lesquels les noms de chiens ne sont pas correctes (ex : articles et autres figurant en lieu et place des noms de chiens) – probablement le résultat de certaines insuffisances du script utilisé pour extraire le nom des chiens dans les textes – ;\n",
    "* Le tableau image_predictions peut être décomposer en deux tableaux (images et prédictions)\n",
    "* Les noms de race de chiens prédites sont tantôt en majuscule, tantôt en minuscule.  \n",
    "\n",
    "L’évaluation visuelle a aussi permis d’identifier des problèmes d’ordre qui suivent :\n",
    "* Les stades des chiens (doggo,floofer,pupper,puppo) peuvent être représentés par une seule variable (stade)\n",
    "* Le tableau `additional_data` devrait faire partie intégrante du tableau `dogs_rating`\n",
    "\n",
    "L’évaluation programmatique quant à elle, a permis d’identifier les problèmes de qualité suivants :\n",
    "\n",
    "* Certains tweets de `dogs_rating` sont des retweets  (colonne `retweeted_status_id` non nulle)\n",
    "* Données manquantes dans le tableau image_predictions (2075 au lieu de 2356) ;\n",
    "* Des tweets ont une fraction numérateur/dénominateur incorrectes.\n",
    "* Les dates du tableau `dogs_rating` sont de type object et non de type datetime ;\n",
    "\n",
    "\n",
    "### Nettoyage des données<a id='cleaning'></a>\n",
    "\n",
    "Dans cette étape j’ai nettoyé à l’aide de codes python les problèmes mentionnés plus haut, commençant par les problèmes d'ordre  pour terminer avec les problèmes de qualité. Le nettoyage de chaque problème a été effectué en trois étapes distinctes : la définition de l’action à faire, le codage de l'action, puis le test qui confirme que le problème a bien été nettoyé.\n",
    "\n",
    "### Conclusion<a id='conclusion'></a>\n",
    "Le projet m’a permis de mettre en œuvre les bonnes pratiques, recommandations et astuces en matière de préparation des données, vues dans le cours et de mieux les comprendre. Ainsi j’ai pu toucher du doigt certaines réalités auxquelles je pourrai être confronté, en tant que future analyste des données, en matière de données sales et désordonnées."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
